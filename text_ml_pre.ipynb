{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trotsak/text/blob/main/text_ml_pre.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXCm1-lxyCu4"
      },
      "source": [
        "**Название проекта: Классификация текстов для интернет-магазина «Викишоп»**."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
        "\n",
        "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
        "\n",
        "Постройте модель со значением метрики качества *F1* не меньше 0.75.\n",
        "\n",
        "**Инструкция по выполнению проекта**\n",
        "\n",
        "1. Загрузите и подготовьте данные.\n",
        "2. Обучите разные модели.\n",
        "3. Сделайте выводы.\n",
        "\n",
        "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
        "\n",
        "**Описание данных**\n",
        "\n",
        "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
      ],
      "metadata": {
        "id": "8Uuu2oRtypqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q catboost contractions"
      ],
      "metadata": {
        "id": "MBgUK2J4ysWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_md -q"
      ],
      "metadata": {
        "id": "bm2eeWk0Kku7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7cu_7BajP24"
      },
      "outputs": [],
      "source": [
        "# работа с операционной системой\n",
        "import os\n",
        "\n",
        "## Импорт библиотек для анализа и визуализации данных\n",
        "\n",
        "# работа с данными в формате таблиц\n",
        "import pandas as pd\n",
        "\n",
        "# работа с многомерными массивами\n",
        "import numpy as np\n",
        "\n",
        "# Импортируем функцию sqrt (квадратный корень) из модуля math\n",
        "from math import sqrt\n",
        "\n",
        "# Импортируем функцию autocorrelation_plot из библиотеки pandas.plotting\n",
        "from pandas.plotting import autocorrelation_plot\n",
        "\n",
        "# визуализация данных\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# импорт функции display для отображения датафреймов и других объектов в Jupyter Notebook\n",
        "from IPython.display import display\n",
        "\n",
        "# Импорт модуля re для работы с регулярными выражениями\n",
        "import re\n",
        "\n",
        "# импорт конфигурационных параметров для настройки отображения графиков\n",
        "from matplotlib import rcParams, rcParamsDefault\n",
        "\n",
        "# расширенные возможности визуализации\n",
        "import seaborn as sns\n",
        "\n",
        "# Импортируем модуль time для работы со временем\n",
        "import time\n",
        "\n",
        "## Импорт библиотек для статистического анализа\n",
        "\n",
        "# статистические функции\n",
        "from scipy import stats as st\n",
        "\n",
        "# Импортируем функцию adfuller из модуля statsmodels.tsa.stattools\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "# Импорт функции для выполнения теста KPSS (Kwiatkowski-Phillips-Schmidt-Shin)\n",
        "# для проверки стационарности временного ряда\n",
        "from statsmodels.tsa.stattools import kpss\n",
        "\n",
        "# Импортируем функции для визуализации автокорреляции и частичной автокорреляции\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "\n",
        "# импорт библиотеки для статистического анализа\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Импорт функции seasonal_decompose из библиотеки statsmodels.\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "\n",
        "## Импорт библиотек для машинного обучения\n",
        "\n",
        "# Импортируем ColumnTransformer для предобработки данных по столбцам\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Импортируем Pipeline для создания конвейера обработки данных и обучения модели\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Импортируем функцию set_config из библиотеки scikit-learn\n",
        "from sklearn import set_config\n",
        "\n",
        "\n",
        "# общая библиотека машинного обучения\n",
        "import sklearn\n",
        "\n",
        "# разделение данных и оценка моделей\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, RandomizedSearchCV\n",
        "\n",
        "# кодирование категориальных переменных и стандартизация\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
        "\n",
        "# Импортируем класс LinearRegression из библиотеки sklearn (подмодуля linear_model)\n",
        "# from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Импортируем класс RandomForestRegressor из библиотеки sklearn (подмодуля ensemble)\n",
        "# from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Импортируем KNNImputer из библиотеки sklearn.impute\n",
        "# from sklearn.impute import KNNImputer\n",
        "\n",
        "# Импорт модели LightGBM\n",
        "# from lightgbm import LGBMRegressor\n",
        "\n",
        "# Импортируем lightgbm как lgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Импорт функции mean_squared_error из библиотеки scikit-learn\n",
        "from sklearn.metrics import mean_squared_error, make_scorer\n",
        "\n",
        "## Импорт библиотеки для обработки предупреждений\n",
        "\n",
        "# управление предупреждениями\n",
        "import warnings\n",
        "\n",
        "# игнорировать предупреждения (если нужно)\n",
        "# warnings.filterwarnings('ignore')\n",
        "\n",
        "import optuna\n",
        "import re\n",
        "import string\n",
        "import requests\n",
        "import nltk\n",
        "from nltk.corpus import stopwords as nltk_stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "wnl = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "stopwords = set(nltk_stopwords.words('english'))\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "# Создание общего прогресс-бара для apply\n",
        "tqdm.pandas(desc=\"Общий прогресс\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kuZxF99Z26vZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoH2VltCjP25"
      },
      "outputs": [],
      "source": [
        "class Color:\n",
        "\n",
        "    \"\"\"\n",
        "    Класс для хранения цветовых кодов для форматирования текстов в терминале.\n",
        "    \"\"\"\n",
        "\n",
        "    PURPLE = '\\033[95m'      # Фиолетовый цвет\n",
        "    CYAN = '\\033[96m'        # Бирюзовый цвет\n",
        "    DARK_CYAN = '\\033[36m'   # Темно-бирюзовый цвет\n",
        "    BLUE = '\\033[94m'        # Синий цвет\n",
        "    GREEN = '\\033[92m'       # Зеленый цвет\n",
        "    YELLOW = '\\033[93m'      # Желтый цвет\n",
        "    RED = '\\033[91m'         # Красный цвет\n",
        "    BOLD = '\\033[1m'         # Жирный текст\n",
        "    UNDERLINE = '\\033[4m'    # Подчеркнутый текст\n",
        "    END = '\\033[0m'          # Сброс формата текста\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3E-5mdVIjP25"
      },
      "outputs": [],
      "source": [
        "# определение констант\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.10\n",
        "CV_COUNTS=5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# системные настройки\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_colwidth', None)"
      ],
      "metadata": {
        "id": "7U0MvoHX27lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDhf8fnBjP25"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jKXID3AjP27"
      },
      "source": [
        "### Настроим параметры отображения графиков в Matplotlib для лучшей визуализации и качества изображения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-i2MzUmjP28"
      },
      "outputs": [],
      "source": [
        "# установка стиля графиков на основе библиотеки Seaborn\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "# Включаем отображение объектов scikit-learn в виде диаграммы\n",
        "set_config(display='diagram')\n",
        "\n",
        "# установка формата изображения SVG для обеспечения более четкого и качественного изображение графиков.\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "\n",
        "# масштабный фактор, который будет использоваться для изменения параметра dpi.\n",
        "factor = 0.8\n",
        "\n",
        "# извлечение значения по умолчанию для точек на дюйм (dpi) из настроек Matplotlib.\n",
        "default_dpi = rcParamsDefault['figure.dpi']\n",
        "\n",
        "# установка разрешения (dpi) для всех фигур путём умножения значения dpi на масштабный фактор.\n",
        "rcParams['figure.dpi'] = default_dpi*factor\n",
        "\n",
        "# включение отображения графиков в Jupyter\n",
        "%matplotlib inline\n",
        "\n",
        "# установка размера диаграмм\n",
        "rcParams['figure.figsize'] = [12.0, 6.0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-rtAR60jP28"
      },
      "source": [
        "## Подготовка"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfRTl3TCjP28"
      },
      "source": [
        "### Загрузим данные из csv-файла в датафрейм."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "cGI3JqXBjP28"
      },
      "outputs": [],
      "source": [
        "## считывание данных из csv-файлов в датафреймы\n",
        "\n",
        "# назначение путей к файлам\n",
        "file_paths = {\n",
        "    'toxic_comments': '/datasets/ toxic_comments.csv'\n",
        "}\n",
        "\n",
        "# словарь для хранения загруженных данных\n",
        "dataframes = {}\n",
        "\n",
        "# проход по всем файлам\n",
        "for name, path in file_paths.items():\n",
        "    try:\n",
        "        if os.path.exists(path):\n",
        "            dataframes[name] = pd.read_csv(path)\n",
        "            print(f'Файл {path} загружен из локального пути.')\n",
        "        else:\n",
        "            url = f'https://code.s3.yandex.net/datasets/{name}.csv'\n",
        "            dataframes[name] = pd.read_csv(url)\n",
        "            print(f'Файл {path} загружен из URL.')\n",
        "    except Exception as e:\n",
        "        print(f'Не удалось загрузить {path}: {e}')\n",
        "\n",
        "# присваивание загруженным датафреймам отдельных переменных\n",
        "comments_data = dataframes['toxic_comments']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZkpPWY3jP29"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwKOWyppjP29"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZNB78V9jP29"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtRJQaYbjP29"
      },
      "source": [
        "## Анализ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtYVpWgyjP29"
      },
      "source": [
        "### Изучим общую информацию о полученном датафрейме\n",
        "Создадим функцию `data_info` для вывода общей информации по датафрейму."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wpq1F71mjP2-"
      },
      "outputs": [],
      "source": [
        "# создание функции для вывода общей информации по датафрейму\n",
        "def data_info(data, dataframe_name):\n",
        "    \"\"\"\n",
        "    Отображает общую информацию о переданном датафрейме.\n",
        "\n",
        "    Функция выполняет следующие операции:\n",
        "    1. Отображение первых нескольких строк датафрейма.\n",
        "    2. Вывод общей информации о датафрейме, включая типы данных и количество ненулевых значений.\n",
        "    3. Отображение статистического описания числовых столбцов.\n",
        "    4. Подсчет и вывод количества пропущенных значений в каждом столбце.\n",
        "    5. Вывод количества явных дубликатов в датафрейме.\n",
        "    6. Отображение списка названий столбцов в датафрейме.\n",
        "    7. Вывод уникальных значений для столбцов с типом данных 'object'.\n",
        "    8. Вывод числа уникальных значений для каждого столбца.\n",
        "    9. Вывод числа дублей для каждого столбца.\n",
        "\n",
        "    Параметры:\n",
        "    ----------\n",
        "    data : pandas.DataFrame\n",
        "        Датафрейм, для которого необходимо вывести информацию.\n",
        "    dataframe_name : str\n",
        "        Имя датафрейма (для отображения в выводе).\n",
        "    \"\"\"\n",
        "\n",
        "    # отображение первых несколько строк датафрейма\n",
        "    print(Color.BOLD + f\"Первые строки датафрейма {dataframe_name}:\\n\" + Color.END)\n",
        "    display(data.head())\n",
        "    print()\n",
        "\n",
        "    # вывод информацию о датафрейме, включая типы данных и количество ненулевых значений\n",
        "    print(Color.BOLD + f\"Общая информация о датафрейме {dataframe_name}:\\n\" + Color.END)\n",
        "    data.info()\n",
        "    print()\n",
        "\n",
        "    # отображение статистического описания числовых столбцов датафрейма\n",
        "    print(Color.BOLD + f\"Статистическое описание числовых столбцов датафрейма {dataframe_name}:\\n\" + Color.END)\n",
        "    display(data.describe())\n",
        "    print()\n",
        "\n",
        "    # отображение количества пропущенных значений в каждом столбце\n",
        "    print(Color.BOLD + f\"Количества пропущенных значений в каждом столбце датафрейма {dataframe_name}:\\n\" + Color.END)\n",
        "    display(data.isna().sum())\n",
        "    print()\n",
        "\n",
        "    # вывод количества явных дубликатов в датафрейме\n",
        "    print(f'Количество явных дубликатов в датафрейме: {Color.RED}{data.duplicated().sum()}{Color.END}.')\n",
        "    print()\n",
        "\n",
        "    # отображение списка названий столбцов в датафрейме\n",
        "    print(Color.BOLD + f\"Cписок названий столбцов в датафрейме {dataframe_name}:\\n\" + Color.END)\n",
        "    display(data.columns.tolist())\n",
        "\n",
        "    # отображение всех уникальных значений и их количества в столбцах типа 'object'\n",
        "    for i in data.columns:\n",
        "        if data[i].dtype == 'object':\n",
        "            unique_values = data[i].unique()\n",
        "            num_unique_values = len(unique_values)\n",
        "            num_duplicates = data[i].duplicated().sum()\n",
        "            print(f'В столбце {Color.BOLD}\\'{i}\\'{Color.END} содержится {num_unique_values} уникальных значений: \\\n",
        "            {Color.BOLD}{unique_values}{Color.END}')\n",
        "            print(f'Число дублей в столбце {Color.BOLD}\\'{i}\\'{Color.END}: {Color.RED}{num_duplicates}{Color.END}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jW6Qc8sWjP2-"
      },
      "source": [
        "#### Общая информация о датафреме `taxi_data`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "wSt-hnaxjP2-"
      },
      "outputs": [],
      "source": [
        "# получение общей информации по датафрейму с помощью функции data_info\n",
        "data_info(comments_data, 'comments_data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipDbc02fjP2-"
      },
      "source": [
        "**Выводы:**\n",
        "\n",
        "В датафрейме `taxi_data` содержится 4416 строк и 2 колонки с численными и временными типами данных. Индекс отсортирован в монотонном порядке.\n",
        "\n",
        "Согласно документации колонки содержат следующую информацию:\n",
        "\n",
        "- `datetime` - время заказов такси,\n",
        "- `num_orders` - количество заказов такси.\n",
        "\n",
        "Подписи колонок соответствуют хорошему стилю написания, пропущенные значения и аномалии отсутствуют, даты расположены в хронологическом порядке, присутствуют дубли, но в данной ситуации это нормально, удалять не будем, количество заказов такси может повторяться.\n",
        "\n",
        "За 1-часовой период: в среднем 84 заказа, типичная нагрузка в 75% случаев составляет до 107 заказов, изменчивость умеренная - стандартное отклонение 45,  максимальное число заказов значительно отличается от значения среднего и медианы - 462, что указывает на наличие всплесков спроса; минимальное число заказов - 0."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "comments_data = comments_data.drop('Unnamed: 0', axis=1)\n",
        "display(comments_data.head())\n",
        "comments_data.info()"
      ],
      "metadata": {
        "id": "byg88TSG8pKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Оптимизируем тип данных признака 'toxic' (int64 переведем в формат uint8):\n",
        "comments_data['toxic'] = comments_data['toxic'].astype('uint8')"
      ],
      "metadata": {
        "id": "xngh-WkkFOd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comments_data.groupby('toxic')['text'].count()"
      ],
      "metadata": {
        "id": "swUzktUf4Z8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tqdm import tqdm\n",
        "# def lemmatize_text(text):\n",
        "\n",
        "#     # Удаляем символы, не относящиеся к русскому алфавиту\n",
        "#     sub_text = re.sub(r'[^a-zA-Z ]', ' ', text)\n",
        "#     join_text = \" \".join(sub_text.split())\n",
        "\n",
        "#     doc = nlp(join_text)\n",
        "\n",
        "#     lemmatized_tokens = []\n",
        "\n",
        "\n",
        "#     # Добавляем прогресс-бар с помощью tqdm\n",
        "#     for token in doc:\n",
        "#         lemmatized_tokens.append(token.lemma_)\n",
        "\n",
        "#     # Удаляем лишние пробелы и объединяем лемматизированные токены\n",
        "#     lem_text = \" \".join(lemmatized_tokens)\n",
        "\n",
        "#     return lem_text"
      ],
      "metadata": {
        "id": "Pl_8ioHq4p8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lemmatize_text(\"The striped bats are hanging on their feet for best\")"
      ],
      "metadata": {
        "id": "9RTAqRg740Oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipe_names"
      ],
      "metadata": {
        "id": "8WHEUuTT5J4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "96nd6Z9p5eqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NVmDitWF5f8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disabled_pipes = [ \"parser\",  \"ner\"]\n",
        "nlp = spacy.load('en_core_web_sm', disable=disabled_pipes)"
      ],
      "metadata": {
        "id": "Y06eefqb5R0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lemm_texts = []\n",
        "\n",
        "# for doc in tqdm(nlp.pipe(comments_data['text'].values, disable = ['ner', 'parser']),\n",
        "#                 total=comments_data.shape[0],\n",
        "#                 desc=\"Обработка текста\"\n",
        "#                 ):\n",
        "#         lemm_text = \" \".join([i.lemma_ for i in doc])\n",
        "#         lemm_texts.append(lemm_text)"
      ],
      "metadata": {
        "id": "KwdJSWL05gn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # import spacy\n",
        "\n",
        "# # # Загрузка модели Spacy для английского языка\n",
        "# # nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# # Исходное предложение\n",
        "# sentence = \"The striped bats are hanging on their feet for best\"\n",
        "\n",
        "# # Применение модели Spacy\n",
        "# doc = nlp(sentence)\n",
        "\n",
        "# # Лемматизированный текст\n",
        "# lemm_text = \" \".join([token.lemma_ for token in doc])\n",
        "\n",
        "# print(\"Исходный текст:\", sentence)\n",
        "# print(\"Лемматизированный текст:\", lemm_text)"
      ],
      "metadata": {
        "id": "CYq5vp128cgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Проверяем первые N строк\n",
        "# for i, lemm_text in enumerate(lemm_texts[:5]):\n",
        "#     print(f\"Текст {i + 1}: {comments_data['text'].iloc[i]}\")\n",
        "#     print(f\"Лемматизированный: {lemm_text}\")\n",
        "#     print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "A-y6oua98SS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Результат\n",
        "# comments_data['lemm_texts'] = lemm_texts"
      ],
      "metadata": {
        "id": "V04Egucb6_EN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# comments_data.head()"
      ],
      "metadata": {
        "id": "cQOmQ3mMEZHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# comments_data['lem_text'] = comments_data['text'].progress_apply(lemmatize_text)\n",
        "# print(comments_data['lem_text'].head())"
      ],
      "metadata": {
        "id": "rrPJ-XKx7OUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загружаем более мощную модель spaCy\n",
        "nlp = spacy.load('en_core_web_md', disable=[\"ner\", \"parser\", \"textcat\"])"
      ],
      "metadata": {
        "id": "ImsI8iCoKIG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import contractions\n",
        "\n",
        "# Функция очистки текста\n",
        "def clean_text(text):\n",
        "    text = contractions.fix(text)  # Разворачивает сокращения\n",
        "    text = text.lower()  # Приводим к нижнему регистру\n",
        "    text = re.sub(r'<.*?>', '', text)  # Удаляем HTML-теги\n",
        "    text = re.sub(r'\\([^)]*\\)', '', text)  # Удаляем текст в скобках\n",
        "    text = re.sub(r'\\d{1,2}:\\d{2}', '', text)  # Убираем время (формат 21:51)\n",
        "    text = re.sub(r'\\d{4}', '', text)  # Удаляем года (например, 2016)\n",
        "    text = re.sub(r'\\b(january|february|march|april|may|june|july|august|september|october|november|december)\\b \\d{1,2},? \\d{4}', '', text)  # Убираем даты\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)  # Оставляем только буквы и пробелы\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Убираем лишние пробелы\n",
        "    return text"
      ],
      "metadata": {
        "id": "9wjouUn3PvjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Функция для очистки текста\n",
        "# def clean_text(text):\n",
        "#     text = text.lower()  # Приводим к нижнему регистру\n",
        "#     text = re.sub(r'\\([^)]*\\)', '', text)  # Удаляем скобки и их содержимое\n",
        "#     text = re.sub(r'\\d{1,2}:\\d{2}', '', text)  # Удаляем время (например, 21:51)\n",
        "#     text = re.sub(r'\\d{4}', '', text)  # Удаляем года (например, 2016)\n",
        "#     text = re.sub(r'\\s+', ' ', text).strip()  # Убираем лишние пробелы\n",
        "#     return text"
      ],
      "metadata": {
        "id": "UR3VW1bFKI6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gkXKC5NDSCa2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Применяем очистку к каждому комментарию\n",
        "comments_data['clean_text'] = comments_data['text'].apply(clean_text)"
      ],
      "metadata": {
        "id": "Ihxa6nzxKJdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extra_stopwords = {\"d'aww\", \"daww\", \"hey\", \"sir\"}  # Расширяем список стоп-слов\n",
        "lemm_texts = []\n",
        "for doc in tqdm(nlp.pipe(comments_data['clean_text'].tolist()), total=len(comments_data), desc=\"Лемматизация\"):\n",
        "\n",
        "    lemm_text = \" \".join([\n",
        "    token.lemma_\n",
        "    for token in doc\n",
        "    if not token.is_stop and            # Исключаем стоп-слова\n",
        "       not token.is_punct and           # Исключаем пунктуацию\n",
        "       token.lemma_ not in extra_stopwords and  # Исключаем дополнительные стоп-слова\n",
        "       len(token.text) > 2              # Убираем слишком короткие слова\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "    # lemm_text = \" \".join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])\n",
        "    # lemm_text = \" \".join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct not in extra_stopwords and len(token.text) > 2])\n",
        "    # lemm_text = \" \".join([token.lemma_ for token in doc if token.text not in extra_stopwords])\n",
        "    lemm_texts.append(lemm_text)\n",
        "\n",
        "comments_data[\"lemm_text\"] = lemm_texts  # Добавляем в DataFrame"
      ],
      "metadata": {
        "id": "dW7Qfa03KJ1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comments_data.head()"
      ],
      "metadata": {
        "id": "GbWiz8x_LOMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверяем первые N строк\n",
        "for i, lemm_text in enumerate(lemm_texts[:5]):\n",
        "    print(f\"Текст {i + 1}: {comments_data['text'].iloc[i]}\")\n",
        "    print(f\"Лемматизированный: {lemm_text}\")\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "2ORe1GKOLO85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Добавим новые признаки"
      ],
      "metadata": {
        "id": "TQTH1GLLyy6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Добавить длину текста как признак\n",
        "\n",
        "# comments_data[\"text_length\"] = comments_data[\"text\"].apply(len)\n",
        "# comments_data[\"word_count\"] = comments_data[\"text\"].apply(lambda x: len(x.split()))"
      ],
      "metadata": {
        "id": "18gL3SaSy4CW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Количество восклицательных и вопросительных знаков\n",
        "\n",
        "# comments_data[\"excl_marks\"] = comments_data[\"text\"].apply(lambda x: x.count(\"!\"))\n",
        "# comments_data[\"quest_marks\"] = comments_data[\"text\"].apply(lambda x: x.count(\"?\"))"
      ],
      "metadata": {
        "id": "FuJf8qVizYDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Процент заглавных букв\n",
        "\n",
        "# comments_data[\"caps_ratio\"] = comments_data[\"text\"].apply(lambda x: sum(1 for c in x if c.isupper()) / len(x) if len(x) > 0 else 0)"
      ],
      "metadata": {
        "id": "uqYWADLpzcqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Наличие токсичных слов\n",
        "\n",
        "# toxic_words = {\"stupid\", \"idiot\", \"hate\", \"dumb\", \"bitch\", \"fuck\", \"suck\", \"moron\"}\n",
        "# comments_data[\"toxic_words_count\"] = comments_data[\"lemm_text\"].apply(lambda x: sum(1 for word in x.split() if word in toxic_words))"
      ],
      "metadata": {
        "id": "iSHCBcjKzm4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Количество ссылок и упоминаний\n",
        "# import re\n",
        "\n",
        "# comments_data[\"num_links\"] = comments_data[\"text\"].apply(lambda x: len(re.findall(r'http[s]?://', x)))\n",
        "# comments_data[\"num_mentions\"] = comments_data[\"text\"].apply(lambda x: len(re.findall(r'@\\w+', x)))"
      ],
      "metadata": {
        "id": "9rWsMWvYzsgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6nfu0QGnzmU7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " преобразовать текст в числовой формат для модели"
      ],
      "metadata": {
        "id": "xOckG8uKRLMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "phWQrM4Byw8j"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-f2swXpDuEje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Векторизация текста (TF-IDF)"
      ],
      "metadata": {
        "id": "gs0FejlruMQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=150_000, ngram_range=(1,2))\n",
        "# X = vectorizer.fit_transform(comments_data[\"lemm_text\"])\n",
        "X = vectorizer.fit_transform(tqdm(comments_data[\"lemm_text\"], desc=\"Векторизация TF-IDF\"))\n",
        "y = comments_data[\"toxic\"]"
      ],
      "metadata": {
        "id": "cwEJ6ZU2_b2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tqdm import tqdm\n",
        "# tqdm.pandas()  # Подключаем tqdm к Pandas\n",
        "\n",
        "# vectorizer = TfidfVectorizer(max_features=100_000, ngram_range=(1,2))\n",
        "\n",
        "# # Прогресс-бар при обработке текстов\n",
        "# X = vectorizer.fit_transform(tqdm(comments_data[\"lemm_text\"], desc=\"Векторизация TF-IDF\"))\n"
      ],
      "metadata": {
        "id": "Cz00I5mlKiAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# vectorizer = TfidfVectorizer(max_features=5000)  # Ограничиваем до 5000 слов\n",
        "# X = vectorizer.fit_transform(comments_data[\"lemm_text\"])\n",
        "# y = comments_data[\"toxic\"]"
      ],
      "metadata": {
        "id": "mDch2joJRMic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# comments_data.info()"
      ],
      "metadata": {
        "id": "XOuFQKvm7qoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Создание матрицы из остальных численных признаков\n",
        "# additional_features = comments_data[[\n",
        "#     \"text_length\", \"word_count\", \"excl_marks\", \"quest_marks\",\n",
        "#     \"caps_ratio\", \"toxic_words_count\", \"num_links\", \"num_mentions\"\n",
        "# ]].values"
      ],
      "metadata": {
        "id": "b0iXmtt98B7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Масштабируем дополнительные признаки\n",
        "# scaler = StandardScaler()\n",
        "# scaled_additional_features = scaler.fit_transform(\n",
        "#     comments_data[[\"text_length\", \"word_count\", \"excl_marks\", \"quest_marks\",\n",
        "#                    \"caps_ratio\", \"toxic_words_count\", \"num_links\", \"num_mentions\"]].values\n",
        "# )"
      ],
      "metadata": {
        "id": "8bgk6MFo9qPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from scipy.sparse import hstack\n",
        "\n",
        "# Объединение TF-IDF с дополнительными признаками\n",
        "# X = hstack([X_tfidf, additional_features])"
      ],
      "metadata": {
        "id": "3GHkFpSB8EDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Целевая переменная\n",
        "# y = comments_data[\"toxic\"]"
      ],
      "metadata": {
        "id": "uayNQaiQ8F_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kxpbQyn38dgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import random\n",
        "\n",
        "# # Строка X[0]\n",
        "# row = X[0]\n",
        "\n",
        "# # Печать случайных 5 ненулевых элементов\n",
        "# sample_indices = random.sample(range(len(row.data)), k=min(5, len(row.data)))  # Случайные индексы\n",
        "# for idx in sample_indices:\n",
        "#     print(f\"Feature {row.indices[idx]}: {row.data[idx]}\")"
      ],
      "metadata": {
        "id": "qXeLkfDpZkJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X\n"
      ],
      "metadata": {
        "id": "7davLVTHX3fZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y.sample(5)"
      ],
      "metadata": {
        "id": "FW6_SSyrYYp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(X.shape)"
      ],
      "metadata": {
        "id": "DzE4dTsGZHOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "id": "-57jDuY0Y_kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aL6twKn-s1sZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Разделение на обучающую и тестовую выборку"
      ],
      "metadata": {
        "id": "2YglP88cuRRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
      ],
      "metadata": {
        "id": "9UntGZ-5uSMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "K62nj44YuaWn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучение модели логистической регрессии"
      ],
      "metadata": {
        "id": "eYc1vesjuc63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(class_weight=\"balanced\", max_iter=100, random_state=RANDOM_STATE)\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "FG7UTWx_uWqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],  # Регуляризация\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear', 'lbfgs']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(LogisticRegression(class_weight=\"balanced\", max_iter=500, random_state=42),\n",
        "                           param_grid, scoring='f1', cv=5, n_jobs=-1)\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "print(f\"Лучшие параметры: {grid_search.best_params_}\")\n",
        "print(f\"Средний F1-score: {grid_search.best_score_:.4f}\")"
      ],
      "metadata": {
        "id": "kBNknehsySQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# param_grid = {\n",
        "#     'C': [0.01, 0.1, 1, 10],  # Чем меньше C, тем сильнее регуляризация\n",
        "#     'penalty': ['l1', 'l2'],  # L1 - Lasso, L2 - Ridge\n",
        "#     'solver': ['liblinear']  # liblinear поддерживает L1\n",
        "# }\n",
        "\n",
        "# grid_search = GridSearchCV(LogisticRegression(class_weight=\"balanced\", max_iter=500, random_state=42),\n",
        "#                            param_grid, scoring='f1', cv=5, n_jobs=-1)\n",
        "# grid_search.fit(X_train, y_train)\n",
        "\n",
        "# best_model = grid_search.best_estimator_\n",
        "\n",
        "# # Оценка лучшей модели\n",
        "# y_pred_best = best_model.predict(X_test)\n",
        "# f1_best = f1_score(y_test, y_pred_best)\n",
        "# print(f\"F1-score лучшей модели: {f1_best:.4f}\")"
      ],
      "metadata": {
        "id": "jvg54tGCIqRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UFrwsVEhyRNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оценка качества модели"
      ],
      "metadata": {
        "id": "MW3ylyE-usoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "# y_pred = model.predict(X_test)\n",
        "\n",
        "# f1 = f1_score(y_test, y_pred)\n",
        "# acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# print(f\"F1-score: {f1:.4f}\")\n",
        "# print(f\"Accuracy: {acc:.4f}\")"
      ],
      "metadata": {
        "id": "_smIOmbtutj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Улучшить векторизацию текста\n",
        "Попробуем TF-IDF с биграммами и триграммами, чтобы учесть соседние слова:"
      ],
      "metadata": {
        "id": "FhNqDbomIQZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from tqdm import tqdm\n",
        "# import numpy as np\n",
        "\n",
        "# vectorizer = TfidfVectorizer(max_features=70_000, ngram_range=(1,2))\n",
        "\n",
        "# batch_size = 10_000  # Размер батча\n",
        "# lemm_texts = comments_data[\"lemm_text\"].tolist()\n",
        "# X_parts = []\n",
        "\n",
        "# for i in tqdm(range(0, len(lemm_texts), batch_size), desc=\"Обработка TF-IDF\"):\n",
        "#     X_part = vectorizer.fit_transform(lemm_texts[i:i+batch_size])\n",
        "#     X_parts.append(X_part)\n",
        "\n",
        "# X = np.vstack(X_parts)  # Объединяем обратно\n"
      ],
      "metadata": {
        "id": "QdrVvlmoKt0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CatBoost"
      ],
      "metadata": {
        "id": "Qbx7XzF9yYhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost -q"
      ],
      "metadata": {
        "id": "zHhmodfxyaj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучим CatBoost с кросс-валидацией (StratifiedKFold для дисбаланса классов):\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# Модель CatBoost\n",
        "cat_model = CatBoostClassifier(iterations=200, depth=4, learning_rate=0.1,\n",
        "                               loss_function='Logloss',\n",
        "                               verbose=100,\n",
        "                               random_state=42,\n",
        "                               od_type=\"Iter\",\n",
        "                               od_wait=50,\n",
        "                               thread_count=-1)\n",
        "\n",
        "\n",
        "# Кросс-валидация (StratifiedKFold для дисбаланса классов)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "cv_scores = cross_val_score(cat_model, X, y, cv=cv, scoring=\"f1\")\n",
        "\n",
        "print(f\"Средний F1-score CatBoost: {cv_scores.mean():.4f}\")\n",
        "print(f\"Разброс значений: {cv_scores}\")\n"
      ],
      "metadata": {
        "id": "xp4jQt7XyeZo",
        "outputId": "a00581b0-3877-42e7-cdae-6c5f6264ca0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-79635489b7d6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mcv_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"f1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Средний F1-score CatBoost: {cv_scores.mean():.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cat_model.fit(X_train, y_train)\n",
        "\n",
        "# # Оценка на тесте\n",
        "# y_pred_cat = cat_model.predict(X_test)\n",
        "# print(f\"F1-score CatBoost: {f1_score(y_test, y_pred_cat):.4f}\")\n"
      ],
      "metadata": {
        "id": "zSLOjutbye4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT"
      ],
      "metadata": {
        "id": "c2BnZbogywGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch datasets -q\n"
      ],
      "metadata": {
        "id": "UsustJsTyfNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_scheduler\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "7ck05Ar9yfvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загружаем предобученный токенизатор BERT\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Токенизация\n",
        "def tokenize_texts(texts):\n",
        "    return tokenizer(texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "\n",
        "# Разбиваем данные\n",
        "X_train, X_test, y_train, y_test = train_test_split(comments_data[\"lemm_text\"], comments_data[\"toxic\"], test_size=0.2, stratify=comments_data[\"toxic\"], random_state=42)\n",
        "\n",
        "# Токенизируем\n",
        "train_encodings = tokenize_texts(X_train.tolist())\n",
        "test_encodings = tokenize_texts(X_test.tolist())\n"
      ],
      "metadata": {
        "id": "8kYVyKOhyf1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Создаём Dataset для PyTorch\n",
        "\n",
        "class ToxicDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels.iloc[idx])\n",
        "        return item\n",
        "\n",
        "# Создаём PyTorch dataset\n",
        "train_dataset = ToxicDataset(train_encodings, y_train)\n",
        "test_dataset = ToxicDataset(test_encodings, y_test)\n",
        "\n",
        "# DataLoader для обучения\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n"
      ],
      "metadata": {
        "id": "rd1YSy7Hyf7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загружаем предобученный BERT для классификации\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)  # Два класса: токсичный / нетоксичный\n",
        "model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "x5tlIZEbygBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Настраиваем оптимизатор и лосс-функцию\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "wDKQwbsjygGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Обучаем BERT\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.train()\n",
        "\n",
        "for epoch in range(3):  # 3 эпохи\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    print(f\"Эпоха {epoch + 1}, Средний loss: {total_loss / len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "id": "_vJNRWD7ygLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Оцениваем качество (F1-score)\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "model.eval()\n",
        "predictions, true_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        logits = outputs.logits\n",
        "        preds = torch.argmax(logits, dim=-1).cpu().numpy()\n",
        "        labels = batch[\"labels\"].cpu().numpy()\n",
        "\n",
        "        predictions.extend(preds)\n",
        "        true_labels.extend(labels)\n",
        "\n",
        "# Оцениваем F1-score\n",
        "f1 = f1_score(true_labels, predictions)\n",
        "print(f\"F1-score BERT: {f1:.4f}\")\n"
      ],
      "metadata": {
        "id": "YFxclBw_ygRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JF7v35yOygW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DdlXXYvFygct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tw98mZk1ygiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S48fj9szygoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3ETItcj5ygtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1DJp6aX3ygyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Объединяем TF-IDF с новыми признаками"
      ],
      "metadata": {
        "id": "W-Hl2y_A0ORI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import scipy.sparse as sp\n",
        "\n",
        "# X_meta = comments_data[[\"text_length\", \"word_count\", \"excl_marks\", \"quest_marks\", \"caps_ratio\", \"toxic_words_count\", \"num_links\", \"num_mentions\"]]\n",
        "# X_meta = sp.csr_matrix(X_meta)  # Преобразуем в sparse-формат\n"
      ],
      "metadata": {
        "id": "nFI-X9br0PPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f\"Размер TF-IDF: {X.shape}\")  # Должно быть (159292, N)\n",
        "# print(f\"Размер X_meta: {X_meta.shape}\")  # Должно быть (159292, M)\n"
      ],
      "metadata": {
        "id": "sdi1OBAW1Ar5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Проверим, есть ли пропущенные значения в comments_data\n",
        "# print(comments_data.isnull().sum())  # Есть ли NaN в колонках?\n",
        "# print(comments_data.shape)  # Должно быть (159292, ...)\n"
      ],
      "metadata": {
        "id": "CAWfkCKO1IQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# comments_data[\"lemm_text\"] = comments_data[\"lemm_text\"].fillna(\"\")\n"
      ],
      "metadata": {
        "id": "8O4YOPq41Nc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(comments_data.index[:5])\n",
        "# print(pd.DataFrame(X.toarray()).index[:5])  # Индексы TF-IDF\n",
        "# print(X_meta.index[:5])  # Индексы доп. признаков\n"
      ],
      "metadata": {
        "id": "QXkX3Mhp1T_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f\"Размер TF-IDF: {X.shape}\")\n",
        "# print(f\"Размер X_meta: {X_meta.shape}\")\n"
      ],
      "metadata": {
        "id": "WY-zooIP1r_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверим размеры данных перед объединением"
      ],
      "metadata": {
        "id": "OEHflldt05Sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_combined = sp.hstack([X, X_meta])  # Объединяем с TF-IDF"
      ],
      "metadata": {
        "id": "go24SueT08WA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(comments_data.shape)  # Должно быть (159292, N)\n",
        "# print(comments_data.isnull().sum())  # Проверяем NaN\n"
      ],
      "metadata": {
        "id": "nwIvwcPL2MdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(comments_data[[\"text_length\", \"word_count\", \"excl_marks\", \"quest_marks\",\n",
        "                    #  \"caps_ratio\", \"toxic_words_count\", \"num_links\", \"num_mentions\"]].isnull().sum())\n"
      ],
      "metadata": {
        "id": "c5GSvku-2R2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import scipy.sparse as sp\n",
        "\n",
        "# X_meta = comments_data[[\"text_length\", \"word_count\", \"excl_marks\", \"quest_marks\",\n",
        "#                         \"caps_ratio\", \"toxic_words_count\", \"num_links\", \"num_mentions\"]]\n",
        "# X_meta = sp.csr_matrix(X_meta)  # Преобразуем в sparse\n",
        "\n",
        "# # Проверяем размеры\n",
        "# print(f\"Размер TF-IDF: {X.shape}\")\n",
        "# print(f\"Размер X_meta: {X_meta.shape}\")\n"
      ],
      "metadata": {
        "id": "Tc6Zd0Y52kdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_combined = sp.hstack([X, X_meta])  # Объединяем с TF-IDF"
      ],
      "metadata": {
        "id": "IhoPPD532w2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "\n",
        "# # Check shapes\n",
        "# print(f\"Shape of X: {X.shape}\")\n",
        "# print(f\"Length of y: {len(y)}\")\n",
        "\n",
        "# # Optionally check for mismatched indices or missing values\n",
        "# if hasattr(X, 'index') and hasattr(y, 'index'):\n",
        "#     print(f\"Mismatched indices? {not np.array_equal(X.index, y.index)}\")\n",
        "\n",
        "# # Example adjust lengths (if you know how to align)\n",
        "# min_length = min(len(X), len(y))\n",
        "# X = X[:min_length]  # Truncate X\n",
        "# y = y[:min_length]  # Truncate y"
      ],
      "metadata": {
        "id": "CVqs6xrp6exr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rows = sparse_matrix.shape[0]\n",
        "# print(f\"Number of rows in sparse matrix: {rows}\")\n",
        "\n",
        "# print(f\"Length of y: {len(y)}\")"
      ],
      "metadata": {
        "id": "5xtrdt1M6zLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.fit(X_combined, y_train)"
      ],
      "metadata": {
        "id": "EF6hYsNv0WR_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}